{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c061fa37-2ff4-471a-8713-b42fad0f10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb5829-d7f4-4a7f-92c8-45bd615c7605",
   "metadata": {},
   "source": [
    "#### Part 1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e4f9c0-8334-4a7b-8326-6c08a7bf6e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                              )\n",
    "training_set = train_datagen.flow_from_directory('training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "            \n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01836115-b984-45d3-9f45-e8545feb05c0",
   "metadata": {},
   "source": [
    "### Preprocessing the Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1249076b-cc36-4578-afe3-113cd06ecdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e3a04-14cd-4fd2-8e29-41f765159541",
   "metadata": {},
   "source": [
    "### Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75879b24-3751-4f46-b6b2-c4eaacd8a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8b70b-97ef-465b-8534-a6b8d2a16950",
   "metadata": {},
   "source": [
    "#### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d32e474-4951-4e0f-8378-5da0f6520f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Panha seth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45cada1-b86f-49ac-97fc-175315f7031d",
   "metadata": {},
   "source": [
    "#### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfd2a97-fcdd-4c8b-b903-e4c74f315576",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ab8bdc-1c64-4a2b-958b-74098c2ff719",
   "metadata": {},
   "source": [
    "#### Flattenning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792d6111-513f-452b-a8df-68b8e53e1031",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e9c32-46c5-45ce-83a2-7664700043cd",
   "metadata": {},
   "source": [
    "#### Full Connetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a004826e-d5ed-4e21-b978-f625db408659",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=32, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1410c557-a7f4-47df-9f01-93985275cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71a6066-6b17-4cb0-8dd3-f2578aba69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae5a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b559a09d-faf8-495f-9a2f-3dcbb5b12952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Panha seth\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6s/step - accuracy: 0.5757 - loss: 0.7549 - val_accuracy: 0.3721 - val_loss: 1.7540\n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2s/step - accuracy: 0.3812 - loss: 1.5634 - val_accuracy: 0.6279 - val_loss: 0.8481\n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5667 - loss: 0.9036 - val_accuracy: 0.9070 - val_loss: 0.5727\n",
      "Epoch 4/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7257 - loss: 0.5740 - val_accuracy: 0.7674 - val_loss: 0.5208\n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8806 - loss: 0.4138 - val_accuracy: 0.6744 - val_loss: 0.5846\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d1ae3523c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0360d80c-1ad8-4171-96e0-4e659df1ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('single_prediction/Sad.png', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'Laught'\n",
    "else:\n",
    "  prediction = 'Sad'\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b6cb696-352b-4374-a8cc-9dda8ec40e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Laught'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92efa798-5ad2-42e0-b1ce-6d7e718dc6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
